let's take a trip back to 2006 Ian McKellen is 67 years old Patrick Stewart 66 Hugh Jackman 38 but that's not really relevant because in X-Men the Last Stand these two guys don't quite look their age their characters were digitally deaged in what is widely known to be the first implementation of this kind of Technology the effect is well I mean you know it looks like the first time they were using this technology but since then there have been many attempts to level up this illusion with varying degrees of success because even at the highest levels of Hollywood it is really hard to pull off if you look at a person and there's something not quite right with her face what our lizard brain is telling us is ooh that person is sick I better stay away because I don't want to get sick that's Kevin Bailey I'm the visual effect supervisor on here he was one of the people tasked with making sure the film making team could pull off an ambitious 53 minutes of daging work for Tom Hanks Robin Wright Paul betney and Kelly Riley or perhaps we should say reaging as these extremely famous faces become much younger and much older than they are right now people that are critical of daging and face replacement they have every right to be we have it all worked out we have it all worked out it's a very very hard effect to pull off because we just we look at human faces all day every day it's the thing that we recognize the most but Kevin and Hollywood have a new film making toolkit one that makes convincingly changing an actor's age much more achievable daging actors is a painstaking process often times we'll 3D scan an actor and build a full three-dimensional version of their head in the computer then from there you have to like build every muscle and how the skin moves when each muscle is activated and how the blood flows in and out of the skin as it moves and where the peach fuzz lies trying to recreate reality from the inside out in that approach and it can yield really impressive results the problem is it is so labor intensive it's like giving birth and since all this meticulous face spping takes place after filming is wrapped there's a huge amount of subjectivity and kind of filtering in between what the actor does and what ends up on the screen which is one of the reasons they felt that a face swap and post wasn't going to cut it for here it was clear that traditional means of de-aging was was never going to work at the quantity that we had to address and certainly not at the Quality consistently throughout the production that we needed and it wasn't until we saw the results of the very first test by uh this company metaphysic that we kind of went ah gosh than thank you know we we can do this metaphysic enabled Elvis to perform on America's Got Talent and also made the backup singers look exactly like the judges it's kind of freaky they helped Eminem dance with his young younger self and brought Ian home back from the dead they're an AI company that's been making waves in Hollywood during a time where there's still some uncertainty and discomfort over the technology they use sophisticated machine learning to generate faces but maybe it's better to let Kevin explain we want Tom to be 20 and then 25 and then 30 and then 35 so we kind of create these groupings of images that we can feed the AI with and teach it um in the same way that if I gave you a book uh that thick you know thousand pages of images of Tom Hanks from all different kinds of places they might be family photos they might be publicity still movie posters images from films he's been in and I said all right Ed you're going to do nothing for the whole week but flip through the pages of that book and just study Tom hanks's face to study his likeness if at the end of that week as long as you're a visual person if I said to you okay now close your eyes and imagine Tom Hanks singing happy birthday to you in the Moonlight even though none of those images had shown that you would still be able to do that very clearly in your head people confuse it for like you know you feed a 10,000 images and it finds the closest one and it kind of collages it onto a person's face it's actually it's not using a single Pixel from any of the data that it's trained on so it's more like it's drawing an entirely new face with every frame as opposed to copying and pasting pieces of other photos onto the same face to assemble a new one you won't find two faces that are alike in in any of the training material and what ended up in the movie this is what machine learning is good at absorbing a bunch of data in this case people's faces and generating something new but the particularly groundbreaking aspect of this implementation was the speed at which you could work which changed the production entirely it's like really fast like it it will do its thing in like you know milliseconds that is what we use to do the live on set face swaps we would have one monitor that had young Tom Hanks on it and one that had him at current day and that was really powerful it allowed for immediate onset course Corrections by the actors themselves because every time after Boba is called cut they would look and kind of go like yeah you know I'm I'm Shuffling a little bit here maybe I you need to stand up more straight to sell the sort of like physicality illusion or ooh I was overacting my youth in that take let's di that back a bit let's do another take and so it really brought the actor into the conversation and allowed them to use it as a tool it also helped them sear away from a situation where an actor has been made to look young but their physicality doesn't feel young like dair's character here in the Irishman he's supposed to be a rugged and tough mobster here and I mean he just looks like my grandfather trying to kick someone while they're down shout out to this guy for selling it though no I'm not a AF and I mean mean no disrespect to the absolute Powerhouse of an actor that Robert DeNiro is obviously this kind of thing just couldn't be addressed because the daging was happening solely at the end of the pipeline it's very easy to look at a 67-year-old acting young and think God they look so young but then if you were to put a 20-year-old face on them they would look like they were a 20-year-old's face on a 40-year-old body right and it's just like very lizard brain reaction it's something deep inside of us that tells us that something isn't quite right if you look Clos ly you can see that the real time daging works on the face but it leaves the ears and the neck untouched that didn't really matter because the other benefits of the realtime feed was that the editors could use the Half Baked footage to assemble early drafts of the film so it was incredible walking away from set with like every shot that was going to be a face swap shot there was already a very rudimentary version but pretty convincing version of it already done it was just just a little soft and then in post- production we used very similar AI tools but much much higher Fidelity so instead of doing you know a face swap in 10 milliseconds it'll take a few minutes but that way we can get like the real film quality High Fidelity results out of it when it comes to making people older I had to ask Kevin about this scene because I found it so moving and the performances are so good especially uh Paul betney Rose she she loved having you all around her she loved this day she loved she loved cooking for you she live for you you should for you dad I was like oh my God it just I really felt it and I I imagine that's one of the scenes where you guys had to age him up a little bit that scene actually was uh almost purely Prosthetics and makeup but with other scenes in the film they were able to marry the physical Prosthetics and digital makeup to create something that wouldn't have been possible with either alone Robin has never been old before so he couldn't train these models on family photos of her at 85 but what we could do is we could use other AI driven tools and workflows to feed images of her from set and say hey give me a version of this with better skin translucency or one that wrinkles around the nose in a way that feels more like stretching skin and less like a flexible prosthetic and so what we ended up doing is employing the same tools that we use for de-aging and helping them for up aging and this mixing of technology is what helped sell so much of the film people kind of talk about AI dehumanizing certain things and in this case I think it really humanized the whole process because it took these people with Decades of experience and allowed them to to use it in order to better the film what we're doing now it's Cutting Edge in the future it's going to be standard Fair hey if you made it this far thank you so much for watching videos like this deep dives into industry Trends and movie technology that have really deep research and Reporting but are still accessible to watch are some of my favorite to make partly because it's something that I wish that I saw more of I watch a lot of breakdowns and deep dive videos geared towards nerds like me that care so much about the tiniest little details of cinematography or animation but here at Vox we want to make great independent journalism that's accessible for anyone whether you're an industry expert or just somebody who's a little bit curious and that's something that we're only able to do thanks to the support of our members so if you like that mission and want to ensure that videos like this this continue to be made on the internet you can support us at vox.com memberships your support means the world to us so thanks to everyone who's already supported and thanks again for watching